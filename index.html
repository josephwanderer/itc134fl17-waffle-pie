<html>
    <head>
        <title>Wafffle Pie Website</title>
        <meta name="description" content="SSC Big web site for ITC134FL17 - Waffle-Pie "/>
        <meta charset="utf-8"/>
        <meta name="viewport" content="width=device-width"/>
        <meta name="robots" content="noindex,nofollow"/>
        <meta http-equiv="X-UA-Compatible" content="IE=edge"/> 
        <script src="http://code.jquery.com/jquery-latest.min.js" type="text/javascript"></script>
        <script src="https://s3.amazonaws.com/menumaker/menumaker.min.js" type="text/javascript"></script>
        <script src="js/script.js"></script>
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="css/big.css"/>
        <link rel="stylesheet" href="css/nav.css"/>
    </head>
    <body>
        <div class="wrapper">
        <header>
    
        <h1>MACHINE LEARNING AND HOW IT AFFECTS THE JOB INDUSTRY</h1>
        </header>
            
            <Article>
    

    <h2>Introduction</h2>
    
    <p>
        Machine learning(ML) is a powerful technique in the field of artificial intelligence (AI) that promises to greatly expand the accuracy and usefuleness of AI.  It provides computers the ability to learn and adapt from existing experience automatically without hard coding. That is to say, given new data, the machine can make projections based on the patterns it has found in comparable data that it has been fed previously.
    </p>
    <p>
        The expansive and adaptive utility of ML based AI, ranging from autonomous vehicles to product design, has the potential to disrupt large swathes of the human labor market as we know it. Complex mathematical methods, such as singular value deposition and back-propagation, are often used to derive “black-box” models, which are models whose internal logic is too complicated or obscure for humans to understand comprehensively and therefore impossible for humans to code explicitly.
    </p>
    <p>
        Data mining is the foundation of machine learning, since ML models are built on top of a deep understanding and discovery of data structure. However, the scope of data mining by itself is limited to data that we know already, while machine learning develops models from these data and applies the models to new data to make predictions and decisions. Having more and better data with which to train ML models makes those models more robust, more accurate and more useful, which makes that data potentially very valuable. In data analytics, the predictive power of machine learning allows data scientists, engineers and analysts to produce reliable, repeatable decisions and insights from historical relationships and trends in the data, making such data again that much more valuable to them.
    </p>

</Article>
        <article>
        <h2>Machine Learning</h2>
         <h2>Introduction (Point: ML is incredibly powerful/useful)</h2>
        <ul>

<li>Point
<ul>
<li>
 Machine Learning is very broadly useful and core to AI because it allows programs to learn and adapt appropriately to new input without hardcoding its behavior
</li>
<li>
But to work, developers need to give it a lot of the right kind of data
</li>
</ul>
</li>

<li>Illustration
<ul>
<li>
 Black Box Models: Machine Learning Algorithms discern patterns in data that would be difficult or impossible to code explicitly
</li>
</ul>
</li>

<li>Explanation
<ul>
<li>
ML models can then make accurate predictions, approriate decision or novel insights when confronted with new data, without anyone knowing how exactly.
</li>
<li>
ML makes large amounts of data much more useful and valuable to us
</li>
</ul>
</li>

</ul>

            </article>
            <article>
            <h2>Examples (Illustration: Some of the many uses. ML pops up in many new disruptive technologies)</h2>

<b>Examples graphic</b>

<ul>

<li>Point
<ul>
<li>
 Autonomous Vehicle technology is a very useful application of ML
</li>
<li>
ML is well suited to the problem of object recognition needed for autonomous vehicles
</li>
</ul>
</li>

<li>Illustration
<ul>
<li>
 Object recognition for Autonomous Vehicles is very hard, must be accurate and must be appropriate to the task ie. vehicles, pedestrians, street signs etc.
</li>
</ul>
</li>

<li>Explanation
<ul>
<li>
With ML, object recognition models can be trained, tested and improved through trial and error by inputing more data and correcting mistakes.
</li>
<li>
Eventually, an accurate and robust object recognition model can be created without having to explicitly account for all possible circumstances/parameters on the road
</li>
</ul>
</li>

</ul>

            </article>
            
            
            <article>
            
            <h1>Types of Machine Learning</h1>
	 <p>There are three primary types of <a href="https://en.wikipedia.org/wiki/Machine_learning">Machine Learning</a> methods:</p>

	 <ul>
 		<li>Supervised</li>
 		<li>Unsupervised</li>
 		<li>Semi-supervised (reinforcement learning)</li> 
	</ul>

	<p>All of these methods use an inter-changeable variety of algorithms for learning. </p>



<h2>Supervised Learning</h2>
	<p>In <a href="https://en.wikipedia.org/wiki/Supervised_learning">Supervised Learning</a>, the examples are already modeled, and the algorithm predicts future data based off previous data.</p> 


<h3>How it works:</h3>
<ol>
	<li>Classification criteria is defined during model building.  </li>
	<li>Clusters can be for any classification criteria (e.g.: shapes, colors, etc.)</li>
	<li>To separate and classify images of cars, colors are grouped into similar clusters by the algorithm.</li>
</ol>



<h2>Unsupervised Learning</h2> 
	<p>In <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">Unsupervised Learning</a>, the algorithm knows nothing about the data, it is completely unmodeled at the start of learning. It is the job of the machine to separate the data into similar groups.</p>

	<p>This type of learning does not contain any outcome variables to predict.</p>


<h3>How it works:</h3>
	<ol>
		<li>Classificaiton criteria is emergent.</li>
		<li>To separate the cars by big and small, the computer would iteratively improve its matching algorithm without any interference from a human.</li>
	</ol>

<h2>Semi-supervised / Reinforcement learning</h2>
 
 <p>In <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">Semi-supervised Learning</a>, the data is mixed (some labeled, some unlabeled). This type of learning is used to improve learning accuracy without the processor cost of Unsupervised Learning. </p>

<h3>How it works:</h3>
	<ol>
	 <li>These algorithms use a mixture of supervised and unsupervised learning.</li>
	 <li>This type of learning is used to model using production data (with a subset of data used for training; and the remaining for actual model predictions)</li>
	</ol>




<h1>Mechanism Behind Machine Learning</h1>

<h2>Artificial Neural Networks (ANN)</h2>
	<p><a href="https://en.wikipedia.org/wiki/Artificial_neural_network">Artificial Neural Networks</a> are learning systems that mimic the human neural networks. Using artificial neurons, machines can use labeled images to help identify like objects in other images. 

	<p><b>Most common use:</b> Supervised, Unsupervised and Reinforcement Learning</p>


<img src = "images/NeuralNetwork.png" alt="Artificial Neural Networks">

<h1>Types of Machine Learning Activities</h1>


<h2>Classification Algorithms</h2>
	<p><a href="https://en.wikipedia.org/wiki/Statistical_classification">Classification algorithms</a> include <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression</a> and <a href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machines</a> (SVM). They are used for things such as spam detection, text labeling, and diabetes diagnosis.   </p>

	<p><b>Most common use:</b> Supervised Learning</p>

<h2>Regression Algorithms</h2>
	<p><a href="https://medium.com/simple-ai/linear-regression-intro-to-machine-learning-6-6e320dbdaf06">Regression Algorithms</a> include <a href="https://en.wikipedia.org/wiki/Linear_regression">Linear Regression</a>. The are used for things such as predicting prices of an item based on its size or weight. </p>

	<p><b>Most common use:</b> Supervised Learning</p>


<h2>Clustering Algorithms</h2>
	<p>Clustering Algorithms include <a href="https://en.wikipedia.org/wiki/K-means_clustering">K-means</a> and <a href="https://en.wikipedia.org/wiki/Latent_class_model">Latent Class Analysis</a> (LCA) are used for things such as grouping customers into different market segmentation. </p>

	<p><b>Most common use:</b> Unsupervised Learning</p>


<h2>Collaborative Filtering Algorithms</h2>
	<p><a href="https://en.wikipedia.org/wiki/Collaborative_filtering">Collaborative Filtering</a> algorithms include <a href="https://bugra.github.io/work/notes/2014-04-19/alternating-least-squares-method-for-collaborative-filtering/">Alternating Least Squares</a> (ALS). These are behind most e-commerce <a hef="https://blog.statsbot.co/recommendation-system-algorithms-ba67f39ac9a3">recommender systems</a>. These algorithms are used for product recommendations for providers like Netflix or Amazon. </p>

	<p>These type of algorithms take information from like minded individuals. So say you tend to like the same movies as another individual, this algorithm will suggest movies from that other individual and vice versa.</p>

	<p><b>Most common use:</b> Unsupervised Learning</p>

<h2>Dimensionality Reduction Algorithms</h2>
	<p><a href="https://en.wikipedia.org/wiki/Dimensionality_reduction">Dimensionality Reduction</a>algorithms include <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principal Component Analysis</a> (PCA). These are used for removing redundant variables in data.</p>

	<p><b>Most common use:</b> Unsupervised Learning</p>
                
            </article>
  
            <article>
            
            <h1>Process of Machine Learning</h1>

	 <p>As we previously discussed Machine learning is the science of simulating the human mind and learning from past experiences in order to improve and develop through time and training. The point here is to create a model that give us most of the time correct predictions or answers. To create that model we need to follow 7 specific steps :</p>

<img src=images/process.png width="600" height="380" style="float: right">

    <ol>
 		<li>Gathering Data</li>
 		<li>Data Preparation</li>
 		<li>Model Training</li> 
        <li>Evaluation</li>
        <li>Parameter Tuning and Predicting</li>  
	</ol>


<h2>1. Gathering Data</h2>
	<p>This is a critical step upon which all the process depend.This step is very important because the quality and quantity of data that we gather will directly determine how good the predictive model can be. Because data science is a vast field of practices aimed at extracting valuable observations from data in any form, qualified data decide the minimum prediction accuracy of the model.</p> 

<h2>2. Data Preparation</h2>
<p>In this step, we load the data that we gathered into a suitable place (Database, Excel sheet…) and prepare it for use in our machine learning training. An important thing to do in this stage is to randomize the ordering. We don’t want the order of the data to affect the training of the machine learning and its accuracy. Then we divide our gathered data into to sort of Datasets : <b>Training Dataset</b>: A dataset that we feed into our machine learning algorithm to train our model and <b>Testing Dataset</b>: A dataset that we use to validate the accuracy of our model but is not used to train the model. It may be called the validation dataset.</p>

<h2>3. Model Training</h2> 
	<p>There are many models that researchers and data scientists have created over the years. Some are very well suited for image data, others for sequences (like text, or music), some for numerical data, others for text-based data. Models are chosen according to the data that we gathered.<br>

	The training process involves using the training dataset and attempting to predict the output with those values. In the beginning, of course it does pretty poorly. But we can compare our model’s predictions with the output that it should produced, and adjust the values such that we will have more correct predictions. This process then repeats</p>

<h2>4. Evaluation</h2> 
	<p>The training is complete and now it’s time to see if the model is any good.This is where we are going to use the testing dataset. Evaluation allows us to test our model against data that has never been used for training. This allows us to see how the model might perform against data that it has not yet seen. Because that is how things are in the real world.</p>

<h2>5. Parameter Tuning and Predicting</h2> 
	<p>In this step, we want to see if we can further improve the training of the model by tuning some parameter that we assumed in the start of the training. Also, it is important to keep an eye in the learning rate of the model in order to keep track of our progres.<br>

	Predicting is the final step when we get the final result of the model predicting an answer for the primary problem that we posed in the beginning. 
</p>

            
            </article>
        
 <section>
        <h2>THE EFFECTS ON THE JOB MARKET</h2>
            <h3>IMPACT ON THE WORKFORCE</h3>
            <p>
            The rapid increase in emerging technologies suggests that they are having a substantial impact on the workforce. 
            </p>
            <p>For example,Derek Thompson writes that “Google is worth $370 billion but has only about 55,000 employees – less than a tenth the size of ATandT’s workforce in its heyday [in the 1960s].<a href="https://www.theatlantic.com/magazine/archive/2015/07/world-without-work/395294/">The Atlantic</a>
            </p>  
            <p>According to economist Andrew McAfee, “we are facing
            a time when machines will replace people for most of the jobs in the current economy, and I believe it will come not in the crazy distant future.” 
                <a href="https://www.huffingtonpost.com/dawn-nakagawa/andrew-mcafee-machine-age_b_6743660.html">Huffing Post</a>
            </p>
        </section>
        <aside>
            <p></p>
            <img src="images/jobLoss.jpg" width="280" height="300">
        </aside>
        <section>    
            <h3>IMPLICATIONS FOR PUBLIC POLICY</h3>
            <p>
            Advanced societies are at a major turning point in terms of how we think about work, leisure, and social benefit delivery.
            </p>
            <p>
            Advanced economies need fewer workers to complete needed tasks, and benefits are delivered mainly through full-time jobs, there is a danger that many people will have difficulties getting health care, pensions, and the income maintenance they need to sustain their lives.
            </p>
            <p>
             When a considerable portion of human labor no longer is necessary to run the economy, we have to rethink income generation, employment, and public policy. <a href="https://www.brookings.edu/wp-content/uploads/2016/06/robotwork.pdf">Brrokings Article</a> 
            </p>
        </section>
        <aside>
            <h3>Public Poliicy Considerations</h3>
            <ol>
            <li>
               Considering a Basic Income Guarantee
            </li>
            <li>
               Revamping the Earned Income Tax Credit 
            </li>
            <li>
               Provide Activity Accounts for Lifetime Learning and Job Retraining
            </li>
            <li>
               Incentives for Volunteerism
            </li>
            <li>
               Encourage Corporate Profit-Sharing
            </li>
            <li>
               Expanding Arts and Culture for Leisure Time
            </li>
            </ol>
        </aside>
            
            <article>
    <h1>Examples</h1>
<p>Whether it is an inquisitive social media data mine generating anticipation of your next google search with an ad banner or Advanced Neural 
    Networks running competing sets of metaheuristic genetic algorithms to optimizing design of components for an aircraft or next generation medical implant, to 
how decisions are arrived at in emergency rooms, machine learning is influencing the material world in ways that are startling to comprehend
   given the near infancy of the technology. 
    </p>

<p>It is easy to get all Phillip K. Dick about it and accept the dominance of our Ai overlords...but then
funny enough, a natural language algorithm programmed with the works of Phillip k. Dick and his letters as a dataset will
do it for you. 
A google search of the news blurb that made the rounds in 2015 turns up a huge % of the daily publications in the english 
language picking up the story of one of David Hanson's uncanny valley spanning automatons telling (it)'s creator that (it) would keep, 
him especially, "in a human zoo".  Science Fiction's predisposition to pessimistic dystopia will not dispel how much fun it is to 
watch the algorithm learn to walk and then run almost exactly like Jack Sparrow.
    </p>
   
<p>Some care will have to be taken to not let machine learning run away from us, Nick Bostrom's prediction of a Superintelligent Ai
emergence within the first third of the 21st century is fast closing and already we have seen reprecussions of too much faith being put in an 
algorithm to operate in our interest autonomously.  The 2010 "glitch" in a high speed trading algorithm that forced a shutdown of 
the New York Stock Exchange is far enough in the rear view that automated trading accounts for between 50% and 75% of buying and selling
on the "trading floor" today.
    
    As impressive as the object recognition capacity of the machine learning that has informed the progress of autonomous vehicles, there 
    are still thorny questions regarding the morality of life and death decisions that will likely be put before said vehicle operatiing in 
    the chaos of the open road, will an ananomous pedestrian be struck to save the vehicle occupant from an oncoming truck?
    </p>
<p>Conceding that the implementation of machine learning can supplant human interaction and increasingly, human imagination to answer problems of immediate 
    concern is not something I would do readily myself, but at this point we all just may be along for the ride.  
    </p>
    <ul>
        <li>   
<a href="http://www.aaai.org/Papers/Workshops/2005/WS-05-11/WS05-11-005.pdf">www.aaai.org</a>
        </li>
        <li>
<a href="https://www.youtube.com/watch?time_continue=110&v=gn4nRCC9TwQ">www.youtube.com</a>
        </li>
        <li>
<a href="https://nickbostrom.com/superintelligence.html">nickbostrom.com</a>
        </li>
        <li>
<a href="https://qz.com/1078602/why-the-new-york-stock-exchange-nyse-still-has-human-brokers-on-the-trading-floor/">qz.com</a>
        </li>
        <li>
<a href="http://www.nytimes.com/2010/05/07/business/economy/07trade.html">www.nytimes.com</a>
        </li>
        <li>
<a href="http://www.sciencedirect.com/science/article/pii/B9780123983640000012">www.sciencedirect.com</a>
        </li>
        <li>
<a href="http://www.annemergmed.com/article/S0196-0644(17)31442-7/fulltext">www.annemergmed.com</a>
        </li>
        
    </ul>
</article>
               
        <footer>
        <small>&copy; 2017, ITC134-Waffles, All Rights Reserved, <a href="http://validator.w3.org/check?uri=referer" target="_blank">Valid HTML</a> ~ <a href="http://jigsaw.w3.org/css-validator/check/referer" target="_blank">Valid CSS</a></small>  
        </footer>
            
        </div>
    </body>
</html>

            
            
            
            